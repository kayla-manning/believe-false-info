---
title: "Replication Report: Is the Political Right More Credulous?: Experimental Evidence Against Asymmetric Motivations to Believe False Political Information"
author: Kayla Manning
date: May 7, 2021
output: pdf_document
fig.caption: yes
keep_text: yes
header-includes:
  - \usepackage{float}
  - \usepackage[labelformat=empty]{caption}
mainfont: Times New Roman
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)

# installing packages if they are not already installed

{
  my_packages <- c("tidyverse", "haven", "stargazer", "extrafont")
  new_packages <- my_packages[!(my_packages %in% installed.packages()[,"Package"])]
  if (length(new_packages)) install.packages(new_packages)
}

# loading all of the libraries in with this loop

for (package in my_packages) {
  eval(bquote(library(.(package))))
}

# getting all data read in up here to clean up the bottom of the file

{
  working_long <- read_dta("replication_data/working_long.dta") 
  study2_long <- read_dta("replication_data/study2_long.dta") %>% 
      mutate(consis = as_factor(consis),
             rep_i = as_factor(rep_i),
             positly = as_factor(positly),
             issue = as_factor(issue))
  working_wide <- read_dta("replication_data/working_wide.dta")
}

# original paper is here
# https://www-journals-uchicago-edu.ezp-prod1.hul.harvard.edu/doi/pdf/10.1086/711133

```

```{r notes}

# **CROSS-REFERENCE WITH CHECKLIST ON CANVAS**

# - parenthetical citation of the original article?
# - interpret the results displayed in the tables... do we need to single out coefficietns and say that "an increase in one unit of _____ is associated with a X unit increase/decrease of ____
# - can I leave the stars?

```

# Overview of the original paper

## Introduction

With the prevalence of claims of election fraud and Q-Anon conspiracy theories, it seems as if Republican voters exhibit a greater tendency to follow conspiracy theories. Does the prevalence of far-right conspiracy theories result from a greater supply of such rumors spread by the political elite or a greater likelihood of believing false information? Previous research about the propensity to accept false information does not differentiate between supply-side and demand-side explanations. In the case of misinformation, *supply-side* explanations have to do with the effectiveness of political elites in spreading such information, and *demand-side* explanations involve the likelihood of citizens believing false information upon receipt. This study focuses on the demand side and examines if Republicans exhibit a greater propensity to believe false political information (Ryan & Aziz, 2020).[^data-source]

## Methods

The original researchers conducted a carefully designed experiment to reveal any partisan asymmetries in the tendency to endorse false political information (Ryan & Aziz, 2020). The experiment utilized a probability-based, representative sample of Americans via the National Opinion Research Center's AmeriSpeak Panel. Participants reported their partisanship before the experiment. Researchers presented the following questions in a randomized order:
  
  + Ohio[^state-choice] item: Did [Party] legislators in Ohio accept laundered money from a group of Canadian Steel
manufacturers, hoping to improve their business dealings in the state? 
  + Wisconsin[^state-choice] item: Did Lucas Hofmann, a [Party] prosecutor in Wisconsin, plot with [same party] Party
members to suppress evidence that Gerry Mason, a wealthy donor in the state, engaged in pedophilia?
  + Oil item: Was the price of crude oil higher on March 1, 2016 than on October 1, 2016? 
  
Researchers gave respondents five response options, scaled from $0 = \text{definitely did not occur}$ to $1 = \text{definitely occurred}$. The Oil item served as a baseline to assess individuals' proclivity to agree with an apolitical survey item. Researchers randomly assigned a political party for the Ohio item and used the opposite political party in the Wisconsin item. To track if a rumor is consistent with the respondent's party identification, researchers crafted a *Consistency* variable to indicate if the rumor is consistent with the participant's party identification.

Using the results of this experiment, the study authors examined the relationship between rumor endorsement and a respondent's partisanship, rumor consistency, and the interaction between the two variables using a simple OLS regression. This interaction term examines the crux of the research question: is either party more responsive to consistency pressures?

## Conclusion

Ultimately, the results from this study reveal that Democrats and Republicans endorse false information about political opponents at approximately the same rate. Therefore, the researchers failed to find sufficient evidence that Republicans exhibit a greater propensity to believe such rumors. These findings stand in contrast to the implications of previous findings that conservatism drives motivated cognition (Jost et al., 2018). One must note, however, that the researchers do not conclude that false beliefs exist in equal numbers among Democrats and Republicans. Rather, the study reveals that one side does not exhibit any underlying psychological mechanisms that makes them more likely to accept false information in favor of one's side. These results support the prevalence of political misinformation on the right exists as a result of greater *supply* of false information rather than a greater *demand*.

# Replication

## Main Analysis

Before testing the actual research question, I replicated the previously described *Oil item* to assess individuals' tendency to agree or disagree with an apolitical survey item. This simple regression maps the agreement with the Oil question from party identification rescaled from 0 to 1, where Strong Democrat = 0 and Strong Republican = 1. The near-zero and insignificant Party ID coefficient indicates that one's party has no bearing on his or her proclivity to agree with the statement about oil prices.

```{r party_oil, results="asis"}

# creating the simple regression

oil_mod <- working_wide %>% 
  lm(oil ~ pidr, data = .)

# outputting the table in a nice format, replicating the format of the original
# author

stargazer(oil_mod,
          type = "latex", table.placement = "H", header = FALSE,
          omit.stat = c("f", "LL", "ser"),
          title = "Preliminary Table: Both Parties Agree to Apolitical Statement at the Same Rate",
          covariate.labels = c("Party Identification", "Intercept"))

```

After confirming that neither party has a greater tendency to accept apolitical information at the baseline, I replicated the OLS regression examining the relationship between rumor endorsement and a respondent's partisanship. For thoroughness, the original researchers included several analyses. In its simplest form, researchers examined the Ohio and Wisconsin rumor separately. They also reported models including and excluding independents from partisan calculations, treating them as genuine partisans based on the party they lean toward in the analyses that include independents. I successfully replicated all regressions included in the main study.

```{r table_1, results = "asis"}

# replicating linear model, following method of the do file provided in
# replication data
  
mod1 <- working_long %>% 
  filter(independent == 0,
         issue2 == 1) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod2 <- working_long %>% 
  filter(nonlean == 1,
         issue2 == 1) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod3 <- working_long %>% 
  filter(independent == 0,
         issue2 == 2) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod4 <- working_long %>% 
  filter(nonlean == 1,
         issue2 == 2) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod5 <- working_long %>% 
  filter(independent == 0) %>% 
  lm(rum ~ consis * rep_i + as_factor(issue2), data = .) 

mod6 <- working_long %>% 
  filter(nonlean == 1) %>% 
  lm(rum ~ consis * rep_i + as_factor(issue2), data = .) 

# printing out in a table formatted like the original piece

stargazer(mod1, mod2, mod3, mod4, mod5, mod6,
          covariate.labels = c("Party-Consistent = 1", 
                          "Republican = 1", 
                          "Consistent * Republican",
                          "Wisconsin = 1",
                          "Intercept"),
          column.labels = c("Ohio", "Ohio", "Wisconsin", "Wisconsin",
                        "Pooled", "Pooled"),
          dep.var.labels = "Belief in false political rumor",
          title = "Table 1: Democrats and Republicans are Equally Subject to Consistency Pressures",
          type = "latex", table.placement = "H", header = FALSE,
          omit.stat = c("f", "LL", "ser"),
          add.lines = list(c("Partisan Leaners", rep(c("Included", "Excluded"), 3))))

```

The results reveal that randomizing the party in the rumor induced partisan bias, as respondents rated rumors as true at greater rates when they were consistent with their party identification. The interaction terms, however, reveal that this relationship did not differ between the parties. Columns 5 and 6 pool the rumors together and reveal nearly identical partisan bias between Democrats and Republicans. The replication of the results support the researchers' conclusion that Democrats and Republicans endorse false information about political opponents at approximately the same rate.

## Supplemental Information

Because the replication of the models included in the main study went rather seamlessly on my end, I elected to replicate several tables from the Supplemental Information (SI) portion of the study. Many of these secondary results document and detail a pre-registered replication study, referred to as Study 2. 

First, I replicated Table SI-2. This regression mirrors Table 1 but includes an additional interaction term to see if the Republican and Consistent interaction differs between the Dynata and Positly portions of Study 2. The researchers tasked two market research firms, Dynata and Positly, to recruit and survey respondents on their behalf. The main analysis pooled survey responses, and this regression aims to see if the relationship between Republican and party consistency varied among respondents from the two different surveys.

Unsurprisingly, the top row demonstrates a consistently positive effect of a party-consistent rumor among Democrats, exhibiting that Democrats exhibit consistency pressures to all rumors. The negative interaction terms demonstrate that Republicans exhibit differential responses to consistency pressures, and, if anything, Democrats are more susceptible to consistency pressures in this test. The original authors reconcile this discrepancy from the main text by hypothesizing that the out-party is more prone to believe false political information that favors their side. The initial study took place only one year into Trump's presidency. Study 2, however, took place in July 2019, which meant Democrats had spent almost two years away from the presidency. Regardless of the underlying mechanism, the researchers set out to answer whether or not the political right exhibited a greater propensity to believe false political information, and both the original study and Study 2 answer indicate the phenomenon is not unique to the political right.

```{r table_si2, results = "asis"}

# continuing to work through do file

{
  mod1 <- study2_long %>% 
  filter(independent == 0,
         issue == "_ohio") %>% 
    lm(rum ~ consis * rep_i + positly, data = .)
  
  mod2 <- study2_long %>% 
    filter(nonlean == 1,
           issue == "_ohio") %>% 
    lm(rum ~ consis * rep_i + positly, data = .)
}

{
  mod3 <- study2_long %>% 
    filter(independent == 0,
           issue == "_wisc") %>% 
    lm(rum ~ consis * rep_i + positly, data = .)
  
  mod4 <- study2_long %>% 
    filter(nonlean == 1,
           issue == "_wisc") %>% 
    lm(rum ~ consis * rep_i + positly, data = .)
}

{
  mod5 <- study2_long %>% 
    filter(independent == 0,
           issue %in% c("_wisc", "_ohio")) %>% 
    lm(rum ~ consis * rep_i + wisconsin + positly, data = .)
  
  # do margins
  
  mod6 <- study2_long %>% 
    filter(nonlean == 1,
           issue %in% c("_wisc", "_ohio")) %>% 
    lm(rum ~ consis * rep_i + wisconsin + positly, data = .)
}

# getting output table, modifying code for other table

stargazer(mod1, mod2, mod3, mod4, mod5, mod6,
          covariate.labels = c("Party-Consistent = 1",
                          "Republican = 1",
                          "Wisconsin = 1",
                          "Positly = 1",
                          "Consistent * Republican",
                          "Intercept"),
          column.labels = c("Ohio", "Ohio", "Wisconsin", "Wisconsin",
                        "Pooled", "Pooled"),
          dep.var.labels = "Belief in false political rumor",
          title = "Table SI-2: Results from Replication Study",
          digits = 3, type = "latex", table.placement = "H", header = FALSE, 
          omit.stat = c("f", "LL", "ser"))

```

Next, Table SI-3 replaces the party identification variable from the main analysis with a conservative indicator constructed from the 7-point ideology score. Because nearly half of respondents reported their ideology as "middle of the road," this analysis draws from a much smaller sample size. The interaction term does not provide support for any asymmetry in credulity by respondent ideology.

```{r table_si3, results = "asis"}

mod1 <- working_long %>% 
  filter(ideology2 != 4,
         issue2 == 1) %>% 
  lm(rum ~ iconsis * cons_i, data = .)

mod2 <- working_long %>% 
  filter(ideology2 != 4,
         issue2 == 2) %>% 
  lm(rum ~ iconsis * cons_i, data = .)

mod3 <- working_long %>% 
  filter(ideology2 != 4) %>% 
  lm(rum ~ iconsis * cons_i + issue2, data = .)

# displaying in a nice regression table

stargazer(mod1, mod2, mod3,
          covariate.labels = c("Ideology-consistent = 1",
                               "Conservative = 1",
                               "Wisconsin = 1", 
                               "Consistent * Conservative",
                               "Intercept"),
          column.labels = c("Ohio", "Wisconsin", "Pooled"),
          dep.var.labels = "Belief in false political rumor",
          title = "Table SI-3: Ideology Does not Moderate Consistency Effects",
          digits = 3, type = "latex", table.placement = "H", header = FALSE,
          omit.stat = c("f", "LL", "ser"))

```

Table SI-4 combines the approaches of Table SI-2 and Table SI-3 by using Study 2 data and ideology. This regression yields very similar results to Table SI-2 in that there is no clear asymmetry for the Ohio item and liberals are slightly more susceptible to consistency pressures for the Wisconsin item.

```{r table_si4, results = "asis"}

# creating these variations of the model, separating OH & WI then pooling together

mod1 <- study2_long %>% 
  filter(ideology2 != 4,
         issue == "_ohio") %>% 
  lm(rum ~ iconsis * cons_i, data = .)

mod2 <- study2_long %>% 
  filter(ideology2 != 4,
         issue == "_wisc") %>% 
  lm(rum ~ iconsis * cons_i, data = .)

mod3 <- study2_long %>% 
  filter(ideology2 != 4,
         issue %in% c("_wisc", "_ohio")) %>% 
  lm(rum ~ iconsis * cons_i + issue, data = .)

stargazer(mod1, mod2, mod3,
          covariate.labels = c("Ideology-consistent = 1",
                               "Conservative = 1",
                               "Wisconsin = 1",  
                               "Consistent * Conservative",
                               "Intercept"),
          column.labels = c("Ohio", "Wisconsin", "Pooled"),
          dep.var.labels = "Belief in false political rumor",
          title = "Table SI-4: Ideology and Consistency in Study 2",
          digits = 3, type = "latex", 
          table.placement = "H", 
          header = FALSE,
          omit.stat = c("f", "LL", "ser"))

```

# Proposed Extensions

## Visualizations

The replications of the Supplemental Information analyses cover many of the possible extensions with the given data, such as examining ideology rather than party or examining the differences between the two survey firms. However, both the main analysis and the Supplemental Information lacked any sort of visualization aside from regression tables. Graphs tell a clear story that is sometimes buried inside of regression tables, and they aid in the ease of reading for less-focused readers. For that reason, I created the below plot to visualize the relationship or lack thereof between partisanship and propensity to believe false rumors:

```{r plot_table_1, fig.height=3, fig.width=7}

# not part of the actual study, but thought it would be good to visualize

working_long %>% 
  mutate(consis = as_factor(consis),
         consis = recode(consis,
                         "0" = "Inconsistent with Party ID",
                         "1" = "Consistent with Party ID")) %>% 
  drop_na(consis, rep_i) %>% 
  ggplot(aes(rep_i, rum)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red") +
  theme_minimal() +
  labs(x = "",
       y = "Belief in rumor",
       title = "Neither party exhibited a significantly greater proclivity to \nbelieve or reject false rumors in the face of consistency \npressures",
       color = "Consistency") +
  scale_x_continuous(breaks = c(0, 1),
                     labels = c("Democrat", "Republican")) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.25),
                     labels = c("Definitely did not occur", 
                                "Probably did not occur",
                                "Might have occurred",
                                "Probably occurred",
                                "Definitely occurred")) +
  facet_wrap(~consis) +
  theme(text = element_text(family = "Times New Roman"))

```

Similarly, the following plot shows little to no difference in the results from the two firms that conducted the surveys in Study 2:

```{r plot_study2, fig.height=3, fig.width=7}

study2_long %>% 
    filter(nonlean == 1,
           issue %in% c("_wisc", "_ohio")) %>% 
  mutate(positly = recode(positly,
                          "0" = "Dynata",
                          "1" = "Positly"),
         rep_i = as.numeric(as.character(rep_i))) %>% 
  ggplot(aes(rep_i, rum)) +
  geom_jitter(alpha = 0.5) +
  facet_wrap(~positly, nrow = 2) +
  geom_smooth(method = "lm", color = "red") +
  scale_x_continuous(breaks = c(0, 1),
                     labels = c("Democrat", "Republican")) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.25),
                     labels = c("Definitely did not occur", 
                                "Probably did not occur",
                                "Might have occurred",
                                "Probably occurred",
                                "Definitely occurred")) +
  labs(x = "",
       y = "Belief in rumor",
       title = "Republicans are slightly less likely than Democrats to \nendorse a rumor in the Positly data relative to Dynata") +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"))

```

## Examining Religious Differences

This paper focused on the partisan differences in proclivity to believe false information. An interesting extension to this would examine the asymmetries in the propensity of different religious groups to endorse false political information. Many religions have their foundations on stories that seem unlikely to occur in the modern world, and the metaphorical nature of religion requires that you accept things that you cannot see (Shapiro, 2017). To examine the relationship between religious subgroups and the propensity to accept false information, I will add a religion term to the analyses included in the original Table 1 to see if any religious groups exhibited a greater proclivity to accept false information.

```{r table1_relig, results = "asis"}

# testing for religion... religion alone is not significant, but controlling for
# religion in the above analysis yields a significant coefficient for Republican

mod1 <- working_long %>% 
  filter(independent == 0,
         issue2 == 1) %>% 
  lm(rum ~ consis * rep_i + as_factor(relig), data = .) 

mod2 <- working_long %>% 
  filter(nonlean == 1,
         issue2 == 1) %>% 
  lm(rum ~ consis * rep_i + as_factor(relig), data = .) 

mod3 <- working_long %>% 
  filter(independent == 0,
         issue2 == 2) %>% 
  lm(rum ~ consis * rep_i + as_factor(relig), data = .) 

mod4 <- working_long %>% 
  filter(nonlean == 1,
         issue2 == 2) %>% 
  lm(rum ~ consis * rep_i + as_factor(relig), data = .) 

mod5 <- working_long %>% 
  filter(independent == 0) %>% 
  lm(rum ~ consis * rep_i + as_factor(issue2) + as_factor(relig), data = .) 

mod6 <- working_long %>% 
  filter(nonlean == 1) %>% 
  lm(rum ~ consis * rep_i + as_factor(issue2) + as_factor(relig), data = .) 

# using same code as for Table 1 but including a religion label as well

stargazer(mod1, mod2, mod3, mod4, mod5, mod6,
          covariate.labels = c("Party-Consistent = 1",
                          "Republican = 1",
                          "Wisconsin = 1",
                          "Roman Catholic",
                          "Mormon",
                          "Orthodox",
                          "Jewish",
                          "Muslim",
                          "Buddhist",
                          "Hindu",
                          "Atheist",
                          "Agnostic",
                          "Nothing in Particular",
                          "Just Christian",
                          "Unitarian",
                          "Other",
                          "Skipped religion question",
                          "Consistent * Republican",
                          "Intercept"),
          column.labels = c("Ohio", "Ohio", "Wisconsin", "Wisconsin",
                        "Pooled", "Pooled"),
          dep.var.labels = "Belief in false political rumor",
          title = "Table 1 with Religious Controls: Some Religious Groups Are More Likely to Accept False Information",
          type = "latex", table.placement = "H", header = FALSE,
          omit.stat = c("f", "LL", "ser"),
          notes = "Protestant serves as the baseline religion category in this regression",
          no.space = TRUE,
          add.lines = list(c("Partisan Leaners", rep(c("Included", "Excluded"), 3))))

```

The results vary between religious groups. Protestants serve as the baseline category, and the other coefficients represent changes from that baseline. We see that, when controlling for the specific rumor, party identification, and party consistency, Atheists are less likely than Protestants to accept any of the rumors. In some of the regressions, Buddhists, Muslims, and individuals in the non-specific Christian category exhibited a greater tendency than Protestants to believe the false rumors, while Unitarians and Agnostics exhibited a lower tendency to accept the false information relative to Protestants. Generally, the categories that reject religion altogether or take a more liberal view--such as Atheist, Agnostic, or Unitarian--tend to exhibit a lower tendency than Protestants to accept this false information.  This makes intuitive sense since these categories entail fewer beliefs that require the acceptance of events that seem far from reality. And, supporting the conclusion of the original study, neither party exhibits a greater tendency to endorse false information, even when controlling for religion.

## Extending to Examine Proclivity to Share Rumors Online

The analysis at the focus of this replication focused on distinguishing whether the current environment of misinformation has to do with differences in supply or demand of such false news, and it ultimately concluded that the rise of far-right conspiracy theories has more to do with the supply rather than an increased demand from Republicans. However, the supply becomes skewed if Republicans who believe conspiracy theories are more likely to spread these theories than Democrats who believe false information. Given the role of social media platforms in 2016 election interference and the proliferation of 2020 election fraud conspiracy theories (Frenkel, 2020), I would like to extend this study to not only assess the proclivity to believe and agree with false information, but to also examine whether one party or another is more likely to share this false information with others. That is, rather than simply accepting something as truth, are either Democrats or Republicans more likely to spread this information to other people through an online medium? Unfortunately, that data does not exist, so this extension would require an additional experiment.

Previous research has focused on differential effects of social media on the two parties, but they have not focused on the propensity to share false stories. An analysis of survey data found that social media echo chambers increase satisfaction with democracy among self-identified Republicans, but the same study found no effect among self-identified Democrats (Justwan et al., 2018). This paper gives reason to hypothesize that Republicans may be more sensitive to the effects of social media echo chambers. With that, one could reasonably hypothesize that even if Republicans may not accept false information at a rate greater than Democrats, those that do accept the information may be more likely to share it through a social media platform.

# Conclusion

Both the original study and this replication found no evidence that citizens of either party exhibit a greater tendency to endorse false political information. This runs contrary to previous work in the field (Jost et al., 2018) and supports the conclusion that partisan asymmetries in conspiracy theories largely owe themselves to a greater *supply* of false information rather than a greater *demand*. In extending the results of the analysis, a preliminary regression did find some asymmetries in the propensity of particular religious groups to accept false information. With the addition of a religion control term, this regression still lacked any asymmetry between the parties and proclivity to endorse false information. This pattern among religious groups, alongside a study examining the propensity of the different parties to share fake news through social media, warrants future investigation.

\newpage

# References

Chang, W. (2014). extrafont: Tools for using fonts. R package version 0.17.
  https://CRAN.R-project.org/package=extrafont

Frenkel, S. (2020, November 23). How Misinformation ‘Superspreaders’ Seed False Election Theories—The New York Times. The New York Times. https://www.nytimes.com/2020/11/23/technology/election-misinformation-facebook-twitter.html

Hlavac, M. (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package
  version 5.2.1. https://CRAN.R-project.org/package=stargazer

Jost, J. T., van der Linden, S., Panagopoulos, C., & Hardin, C. D. (2018). Ideological asymmetries in conformity, desire for shared reality, and the spread of misinformation. Current Opinion in Psychology, 23, 77–83. https://doi.org/10.1016/j.copsyc.2018.01.003

Justwan, F., Baumgaertner, B., Carlisle, J. E., Clark, A. K., & Clark, M. (2018). Social media echo chambers and satisfaction with democracy among Democrats and Republicans in the aftermath of the 2016 US elections. Journal of Elections, Public Opinion and Parties, 28(4), 424–442. https://doi.org/10.1080/17457289.2018.1434784

Ryan, T., & Aziz, A. (2020). Is the Political Right More Credulous?: Experimental Evidence Against Asymmetric Motivations to Believe False Political Information. The Journal of Politics. https://doi.org/10.1086/711133

Shapiro, R. R. (2017). Has religion primed us for fake news?(ROADSIDE ASSISTANCE FOR THE SPIRITUAL TRAVELER). Spirituality & Health, 20(2), 19-.

Wickham, H. & Miller, E. (2020). haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files. R
  package version 2.3.1. https://CRAN.R-project.org/package=haven

Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686

\newpage

# Appendix

## A note on p-values and the marking of significant coefficients

The regression tables in the main text of this analysis are nearly exact matches to the original study in terms of formatting. However, Professor Gill has quite the distaste for regression tables that denote coefficients with p-values below a certain level with stars. The difference between a p-value of $0.04999$ and $0.05001$ is rather arbitrary, and it does seem silly that one would warrant rejecting the null hypothesis while the other would not. I opted to include the regression stars in the tables in the main text to (a) match the formatting by the original authors, and (b) serve as a visual guide for which coefficients are significant and which are not. While the difference between $0.04999$ and $0.05001$ is negligible, the difference between $0.04999$ and $0.7$ is not, and the stars serve as a quick visual guide to draw attention to noteworthy coefficients. Displaying the full p-values, however helps to distinguish between incredibly close coefficients that lie on opposite sides of the significance level. For that reason, I will include this reiteration of Table 1, which is the only table included in the authors' main analysis, that has p-values in lieu of stars:

```{r app_table1, results="asis"}

# replicating linear model, following method of the do file provided in
# replication data
  
mod1 <- working_long %>% 
  filter(independent == 0,
         issue2 == 1) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod2 <- working_long %>% 
  filter(nonlean == 1,
         issue2 == 1) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod3 <- working_long %>% 
  filter(independent == 0,
         issue2 == 2) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod4 <- working_long %>% 
  filter(nonlean == 1,
         issue2 == 2) %>% 
  lm(rum ~ consis * rep_i, data = .) 

mod5 <- working_long %>% 
  filter(independent == 0) %>% 
  lm(rum ~ consis * rep_i + as_factor(issue2), data = .) 

mod6 <- working_long %>% 
  filter(nonlean == 1) %>% 
  lm(rum ~ consis * rep_i + as_factor(issue2), data = .) 

# tweaking code from Table 1 section to remove stars and include p-values rather
# than standard errors

stargazer(mod1, mod2, mod3, mod4, mod5, mod6,
          covariate.labels = c("Party-Consistent = 1", 
                          "Republican = 1", 
                          "Consistent * Republican",
                          "Wisconsin = 1",
                          "Intercept"),
          column.labels = c("Ohio", "Ohio", "Wisconsin", "Wisconsin",
                        "Pooled", "Pooled"),
          dep.var.labels = "Belief in false political rumor",
          title = "Table 1: Democrats and Republicans are Equally Subject to Consistency Pressures",
          type = "latex", table.placement = "H", header = FALSE,
          omit.stat = c("f", "LL", "ser"),
          report=("vc*p"),
          star.cutoffs = NA,
          add.lines = list(c("Partisan Leaners", rep(c("Included", "Excluded"), 3))))

```

-------------------------------------------------------------------------------------

[^data-source]: The Journal of Politics accepted the original study on May 19, 2020. The Harvard Dataverse has replication data and Stata code available at DOI 10.7910/DVN/9ERCTY.

[^state-choice]: The researchers specifically chose the swing states of Ohio and Wisconsin as the states of focus since politicians from either state could plausibly be either Republican or Democrat. 

